{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install allensdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.core.cell_types_cache import CellTypesCache\n",
    "from allensdk.ephys.extract_cell_features import extract_cell_features\n",
    "from allensdk.ephys.extract_cell_features import extract_sweep_features\n",
    "from collections import defaultdict\n",
    "from allensdk.core.cell_types_cache import CellTypesCache\n",
    "from allensdk.api.queries.cell_types_api import CellTypesApi\n",
    "from allensdk.core.cell_types_cache import ReporterStatus as RS\n",
    "# Instantiate the CellTypesCache instance.  The manifest_file argument\n",
    "# tells it where to store the manifest, which is a JSON file that tracks\n",
    "# file paths.  If you supply a relative path it will go into your\n",
    "# current working directory\n",
    "ctc = CellTypesCache()\n",
    "from allensdk.core.nwb_data_set import NwbDataSet\n",
    "import pickle \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = ctc.get_cells(species=[CellTypesApi.HUMAN])\n",
    "# download all cells(cache)\n",
    "# get sequence list\n",
    "def get_sequenceList():\n",
    "    cells = ctc.get_cells()\n",
    "#     print(\"Total cells: %d\" % len(cells))\n",
    "    specimen_id_list=[]\n",
    "    for i in range(0, len(cells)):\n",
    "        specimen_id_list.append(cells[i]['id'])\n",
    "    return specimen_id_list\n",
    "\n",
    "specimen_id_list=get_sequenceList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# download all cells(cache)\n",
    "# get sequence list\n",
    "def get_human_sequenceList():\n",
    "    cells = ctc.get_cells(species=[CellTypesApi.HUMAN])\n",
    "#     print(\"Total cells: %d\" % len(cells))\n",
    "    specimen_id_list=[]\n",
    "    for i in range(0, len(cells)):\n",
    "        specimen_id_list.append(cells[i]['id'])\n",
    "    return specimen_id_list\n",
    "\n",
    "specimen_id_human_list=get_human_sequenceList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data for each specimen_id(do not run this, already downloaded)\n",
    "def download_data(specimen_id_list):\n",
    "    try:\n",
    "        for i in range(0,len(specimen_id_list)):\n",
    "            ctc.get_ephys_data(specimen_id_list[i])\n",
    "    except:\n",
    "        print(\"Error while downloading\")\n",
    "    return \"Files downloaded\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def stimulus_response_long_square(stimulus_value,specimen_id_list):\n",
    "    i=[]\n",
    "    v=[]\n",
    "    t=[]\n",
    "    spec_id=[]\n",
    "    dataset={}\n",
    "    for specimen_id in specimen_id_list:\n",
    "        data_set_dir='/share/quonlab/data/allen/'\n",
    "        specimen_filename='specimen_'+str(specimen_id)+'/ephys.nwb'\n",
    "        file_name = data_set_dir+specimen_filename\n",
    "        data_set = NwbDataSet(file_name)\n",
    "        sweeps = ctc.get_ephys_sweeps(specimen_id) \n",
    "        # groups the sweeps by stimulus \n",
    "        sweep_numbers = defaultdict(list)\n",
    "        for sweep in sweeps:\n",
    "            sweep_numbers[sweep['stimulus_name']].append(sweep['sweep_number'])\n",
    "\n",
    "        for sweep_number in sweep_numbers['Long Square']:\n",
    "            sweep_metadata=data_set.get_sweep_metadata(sweep_number)\n",
    "            #change the range accordingly \n",
    "            if int(sweep_metadata['aibs_stimulus_amplitude_pa']) in range(stimulus_value,stimulus_value+1) and specimen_id not in spec_id:\n",
    "                sweep_data = data_set.get_sweep(sweep_number)\n",
    "    #             # sampling rate is in Hz\n",
    "                sampling_rate = sweep_data['sampling_rate']\n",
    "                if int(sampling_rate) == 200000:\n",
    "    #                 samplingRate.append(specimen_id)\n",
    "                    index_range = sweep_data[\"index_range\"]\n",
    "                    temp_i = sweep_data[\"stimulus\"][0:index_range[1]+1] # in A\n",
    "                    temp_v = sweep_data[\"response\"][0:index_range[1]+1] # in V\n",
    "                    temp_i *= 1e12 # to pA\n",
    "                    temp_v *= 1e3 # to mV\n",
    "                    temp_t = np.arange(0, len(temp_v)) * (1.0 / sampling_rate)\n",
    "                    start_idx=np.where(temp_t==1.01)[0][0]\n",
    "                    end_idx=np.where(temp_t==2.02)[0][0]\n",
    "                    temp_t = temp_t[start_idx:end_idx][0::2]\n",
    "                    temp_i = temp_i[start_idx:end_idx][0::2]\n",
    "                    #change this to common denominator \n",
    "                    temp_v=temp_v[start_idx:end_idx][0::2]\n",
    "                    i.append(temp_i)\n",
    "                    v.append(temp_v)\n",
    "                    t.append(temp_t)\n",
    "                    dataset[specimen_id]={'i':temp_i,'v':temp_v,'t':temp_t}\n",
    "                else:\n",
    "    #                 samp_notEqual.append(sampling_rate)\n",
    "    #                 specid_notEqual.append(specimen_id)\n",
    "                    index_range = sweep_data[\"index_range\"]\n",
    "                    temp_i = sweep_data[\"stimulus\"][0:index_range[1]+1] # in A\n",
    "                    temp_v = sweep_data[\"response\"][0:index_range[1]+1] # in V\n",
    "                    temp_i *= 1e12 # to pA\n",
    "                    temp_v *= 1e3 # to mV\n",
    "                    temp_t = np.arange(0, len(temp_v)) * (1.0 / sampling_rate)\n",
    "                      #change this to common denominator \n",
    "                    start_idx=np.where(temp_t==1.01)[0][0]\n",
    "                    end_idx=np.where(temp_t==2.02)[0][0]\n",
    "                    temp_t = temp_t[start_idx:end_idx][0::5]\n",
    "                    temp_i = temp_i[start_idx:end_idx][0::5]\n",
    "                    temp_v=temp_v[start_idx:end_idx][0::5]\n",
    "                    i.append(temp_i)\n",
    "                    v.append(temp_v)\n",
    "                    t.append(temp_t)\n",
    "                    dataset[specimen_id]={'i':temp_i,'v':temp_v,'t':temp_t}\n",
    "\n",
    "                spec_id.append(specimen_id)\n",
    "    print(spec_id)\n",
    "\n",
    "    data_dict={\n",
    "        'i':i,\n",
    "        'v':v,\n",
    "        't':t,\n",
    "        'id':spec_id        \n",
    "    }\n",
    "    with open ('human_cells_170_stimulus.pkl','wb') as pf:\n",
    "        pickle.dump(data_dict,pf)\n",
    "#     with open ('humancell_dataset_170_stimulus_longSq.pkl','wb') as pf:\n",
    "#         pickle.dump(dataset,pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def stimulus_response_noise1(stimulus_value,specimen_id_list):\n",
    "    i=[]\n",
    "    v=[]\n",
    "    t=[]\n",
    "    spec_id=[]\n",
    "    for specimen_id in specimen_id_list:\n",
    "        data_set_dir='/share/quonlab/data/allen/'\n",
    "        specimen_filename='specimen_'+str(specimen_id)+'/ephys.nwb'\n",
    "        file_name = data_set_dir+specimen_filename\n",
    "        data_set = NwbDataSet(file_name)\n",
    "        sweeps = ctc.get_ephys_sweeps(specimen_id) \n",
    "        # groups the sweeps by stimulus \n",
    "        sweep_numbers = defaultdict(list)\n",
    "        for sweep in sweeps:\n",
    "            sweep_numbers[sweep['stimulus_name']].append(sweep['sweep_number'])\n",
    "            \n",
    "        if 'Noise 1' in sweep_numbers:\n",
    "            for sweep_number in sweep_numbers['Noise 1']:\n",
    "                sweep_metadata=data_set.get_sweep_metadata(sweep_number)\n",
    "                if int(sweep_metadata['aibs_stimulus_amplitude_pa']) in range(stimulus_value,700) and specimen_id not in spec_id:\n",
    "                    sweep_data = data_set.get_sweep(sweep_number)\n",
    "                    sampling_rate = sweep_data['sampling_rate']\n",
    "                    if int(sampling_rate) == 200000:\n",
    "                        try:\n",
    "                            index_range = sweep_data[\"index_range\"]\n",
    "#                             temp_i = sweep_data[\"stimulus\"][0:index_range[1]+1] # in A\n",
    "                            temp_v = sweep_data[\"response\"][0:index_range[1]+1] # in V\n",
    "#                             temp_i *= 1e12 # to pA\n",
    "                            temp_v *= 1e3 # to mV\n",
    "                            temp_t = np.arange(0, len(temp_v)) * (1.0 / sampling_rate)\n",
    "                            start_idx=np.where(temp_t==2.02)[0][0]\n",
    "                            end_idx=np.where(temp_t==22.01)[0][0]\n",
    "#                             temp_t = temp_t[start_idx:end_idx][0::4]\n",
    "#                             temp_i = temp_i[start_idx:end_idx][0::4]\n",
    "                            temp_v=temp_v[start_idx:end_idx][0::2]\n",
    "#                             i.append(temp_i)\n",
    "                            v.append(temp_v)\n",
    "#                             t.append(temp_t)\n",
    "                        except:\n",
    "                            print(\"error ocurred for\",specimen_id)\n",
    "                    else:\n",
    "                        index_range = sweep_data[\"index_range\"]\n",
    "#                         temp_i = sweep_data[\"stimulus\"][0:index_range[1]+1] # in A\n",
    "                        temp_v = sweep_data[\"response\"][0:index_range[1]+1] # in V\n",
    "#                         temp_i *= 1e12 # to pA\n",
    "                        temp_v *= 1e3 # to mV\n",
    "                        temp_t = np.arange(0, len(temp_v)) * (1.0 / sampling_rate)\n",
    "                        start_idx=np.where(temp_t==2.02)[0][0]\n",
    "                        end_idx=np.where(temp_t==22.01)[0][0]\n",
    "#                         temp_t = temp_t[start_idx:end_idx]\n",
    "#                         temp_i = temp_i[start_idx:end_idx]\n",
    "                        temp_v=temp_v[start_idx:end_idx][0::5]\n",
    "#                         i.append(temp_i)\n",
    "                        v.append(temp_v)\n",
    "#                         t.append(temp_t)\n",
    "\n",
    "                    spec_id.append(specimen_id)\n",
    "#uncomment if you want to save in pickle format            \n",
    "#     data_dict={\n",
    "#         'i':i,\n",
    "#         'v':v,\n",
    "#         't':t\n",
    "#     }\n",
    "#     with open ('voltage_pick_noise1.pkl','wb') as pf:\n",
    "#         pickle.dump(data_dict,pf)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickleFile(filename):\n",
    "    # returns dump pickle file object\n",
    "    with open (filename,'rb') as pf:\n",
    "        new_data=pickle.load(pf)\n",
    "    return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='human_cells_170_stimulus.pkl'\n",
    "new_data=read_pickleFile(filename)\n",
    "i=new_data['i']\n",
    "t=new_data['t']\n",
    "v=new_data['v']\n",
    "ids=new_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to df\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "stimulus_df = pd.DataFrame(i[0],columns=[\"stimulus\"])\n",
    "response_df = pd.DataFrame(v[0],columns=[\"response\"])\n",
    "time_df = pd.DataFrame(t[0],columns=[\"time\"])\n",
    "for i_index in range(1,len(i)):\n",
    "    response_df=response_df.append(pd.DataFrame(v[i_index],columns=[\"response\"]),ignore_index=True)\n",
    "    stimulus_df=stimulus_df.append(pd.DataFrame(i[i_index],columns=[\"stimulus\"]),ignore_index=True)\n",
    "    time_df=time_df.append(pd.DataFrame(t[i_index],columns=[\"time\"]),ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=time_df.join(stimulus_df)\n",
    "df=df.join(response_df)\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to extract metadata\n",
    "import numpy as np\n",
    "import h5py\n",
    "def extract_age(specimen_id_list):\n",
    "    spec_id=[]\n",
    "    id_age={}\n",
    "    details={}\n",
    "    for specimen_id in specimen_id_list:\n",
    "        print(specimen_id)\n",
    "        data_set_dir='/share/quonlab/data/allen/'\n",
    "        specimen_filename='specimen_'+str(specimen_id)+'/ephys.nwb'\n",
    "        file_name = data_set_dir+specimen_filename\n",
    "        data=0\n",
    "        sex=''\n",
    "        with h5py.File(file_name, 'r') as fi:\n",
    "            for key in fi.keys():\n",
    "                group = fi['general']['subject']\n",
    "                if key == 'general':\n",
    "#                     print(group)\n",
    "                    for key in group.keys():\n",
    "            #             print(key)\n",
    "                        if key=='age':\n",
    "                            data = group[key].value\n",
    "                            print(data)\n",
    "                        if key=='sex':\n",
    "                            sex = group[key].value\n",
    "#                             print(data)    \n",
    "    \n",
    "#         ages.append(data) \n",
    "        id_age[specimen_id]={'sex':sex,\"age\":data}\n",
    "        fi.close()\n",
    "    return id_age,new_data\n",
    "       print(key)\n",
    "\n",
    "id_age,new_data=extract_age(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
